// Copyright (2021) Cobalt Speech and Language Inc.

// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package cobaltspeech.diatheke.v4;

import "cobaltspeech/cubic/v5/cubic.proto";

option go_package = ".;diathekepb";
option java_package = "com.cobaltspeech.diatheke";

// Service that implements the Cobalt Diatheke Dialog Management API.
service DiathekeService {
  // Returns version information from the server.
  rpc Version(VersionRequest) returns (VersionResponse) {}

  // ListModels returns information about the Diatheke models
  // the server can access.
  rpc ListModels(ListModelsRequest) returns (ListModelsResponse) {}

  // Create a new Diatheke session. Also returns a list of
  // actions to take next.
  rpc CreateSession(CreateSessionRequest) returns (CreateSessionResponse) {}

  // Delete the session. Behavior is undefined if the given
  // TokenData in the request is used again after this function is called.
  rpc DeleteSession(DeleteSessionRequest) returns (DeleteSessionResponse) {}

  // Process input for a session and get an updated session with
  // a list of actions to take next. This is the only method
  // that modifies the Diatheke session state.
  rpc UpdateSession(UpdateSessionRequest) returns (UpdateSessionResponse) {}

  // Create an ASR stream. A result is returned when the
  // stream is closed by the client (which forces the ASR to
  // endpoint), or when a transcript becomes available on its
  // own, in which case the stream is closed by the server.
  // The ASR result may be used in the UpdateSession method.
  // <br/><br/>
  // If the session has a wakeword enabled, and the client
  // application is using Diatheke and Cubic to handle the
  // wakeword processing, this method will not return a
  // result until the wakeword condition has been satisfied.
  // Utterances without the required wakeword will be
  // discarded and no transcription will be returned.
  rpc StreamASR(stream StreamASRRequest) returns (StreamASRResponse) {}

  // Create a TTS stream to receive audio for the given reply.
  // The stream will close when TTS is finished. The client
  // may also close the stream early to cancel the speech
  // synthesis.
  rpc StreamTTS(StreamTTSRequest) returns (stream StreamTTSResponse) {}

  // Create an ASR stream for transcription. Unlike StreamASR,
  // Transcribe does not listen for a wakeword. This method
  // returns a bi-directional stream, and its intended use is
  // for situations where a user may say anything at all, whether
  // it is short or long, and the application wants to save the
  // transcript (e.g., take a note, send a message).
  // <br/><br/>
  // The first message sent to the server must be the TranscribeAction,
  // with remaining messages sending audio data.
  // Messages received from the server will include the current
  // best partial transcription until the full transcription is
  // ready. The stream ends when either the client application
  // closes it, a predefined duration of silence (non-speech)
  // occurs, or the end-transcription intent is recognized.
  rpc Transcribe(stream TranscribeRequest) returns (stream TranscribeResponse) {}
}

// The top-level message sent by the client for the `Version` method.
message VersionRequest {}

// Lists the version of Diatheke and the engines it uses.
message VersionResponse {
  // Dialog management engine
  string diatheke = 1;

  // NLU engine
  string chosun = 2;

  // ASR engine
  string cubic = 3;

  // TTS engine
  string luna = 4;
}

// The top-level message sent by the client for the `ListModels` method.
message ListModelsRequest {}

// A list of models available on the Diatheke server.
message ListModelsResponse {
  repeated ModelInfo models = 1;
}

// The top-level message sent by the client for the `CreateSession` method.
message CreateSessionRequest {
  // Specifies the Diatheke model ID to use for the session.
  string model_id = 1;

  // Specifies a custom wakeword to use for this session. The
  // wakeword must be enabled in the Diatheke model for this
  // to have any effect. It will override the default wakeword
  // specified in the model.
  string wakeword = 2;
}

// The top-level message sent by the server for the `CreateSession` method.
message CreateSessionResponse {
  SessionOutput session_output = 1;
}

// The top-level message sent by the client for the `DeleteSession` method.
message DeleteSessionRequest {
  TokenData token_data = 1;
}

// The top-level message sent by the server for the `DeleteSession` method.
message DeleteSessionResponse {}

// The top-level message sent by the client for the `UpdateSession` method.
message UpdateSessionRequest {
  SessionInput session_input = 1;
}

// The top-level message sent by the server for the `UpdateSession` method.
message UpdateSessionResponse {
  SessionOutput session_output = 1;
}

// The top-level message sent by the client for the `StreamTTS` method.
message StreamTTSRequest {
  ReplyAction reply_action = 1;

  // Format of the synthesized audio.
  StreamTTSAudioFormat audio_format = 2;
}

message StreamTTSAudioFormat {
  // Sampling rate in Hz. This is a required field.
  uint32 sample_rate = 1;

  // Codec of the synthesized audio. It must be specified explicitly and using the
  // default value of `AUDIO_CODEC_UNSPECIFIED` will result in an error.
  AudioCodec codec = 2;

  // Encoding of the synthesized audio. It must be specified explicitly and using the
  // default value of `AUDIO_ENCODING_UNSPECIFIED` will result in an error.
  AudioEncoding encoding = 3;

  // Bit depth of each sample (e.g. 8, 16, 24, 32, etc.). This is a required
  // field.
  uint32 bit_depth = 4;

  // Byte order of the samples. This field must be set to a value other than
  // `BYTE_ORDER_UNSPECIFIED` when the `bit_depth` is greater than 8.
  ByteOrder byte_order = 5;
}

// Byte order of multi-byte data
enum ByteOrder {
  // BYTE_ORDER_UNSPECIFIED is the default value of this type.
  BYTE_ORDER_UNSPECIFIED = 0;

  // Little Endian byte order
  BYTE_ORDER_LITTLE_ENDIAN = 1;

  // Big Endian byte order
  BYTE_ORDER_BIG_ENDIAN = 2;
}

// The encoding of the audio data
enum AudioEncoding {
  // AUDIO_ENCODING_UNSPECIFIED is the default value of this type and will
  // result in an error.
  AUDIO_ENCODING_UNSPECIFIED = 0;

  // PCM signed-integer
  AUDIO_ENCODING_SIGNED = 1;

  // PCM unsigned-integer
  AUDIO_ENCODING_UNSIGNED = 2;

  // PCM IEEE-Float
  AUDIO_ENCODING_IEEE_FLOAT = 3;
}

// The codec of the audio data
enum AudioCodec {
  // AUDIO_CODEC_UNSPECIFIED is the default value of this type and will
  // result in an error.
  AUDIO_CODEC_UNSPECIFIED = 0;

  // RAW audio format
  AUDIO_CODEC_RAW = 1;
}

// The top-level message sent by the server for the `StreamTTS` method.
// Contains synthesized speech audio. The specific encoding
// is defined in the server config file.
message StreamTTSResponse {
  bytes audio = 1;
}

// Information about a single Diatheke model.
message ModelInfo {
  // Diatheke model ID, which is used to create a new session.
  string id = 1;

  // Pretty model name, which may be used for display purposes.
  string name = 2;

  // Language code of the model.
  string language = 3;

  // The ASR audio sample rate, if ASR is enabled.
  uint32 asr_sample_rate = 4;

  // The TTS audio sample rate, if TTS is enabled.
  uint32 tts_sample_rate = 5;
}

// Used by Diatheke to update the session state.
message SessionInput {
  // The session token.
  TokenData token = 1;

  oneof input {
    // Process the user supplied text.
    TextInput text = 2;

    // Process an ASR result.
    ASRResult asr = 3;

    // Process the result of a completed command.
    CommandResult cmd = 4;

    // Change the current session state.
    SetStory story = 5;
  }
}

// A token that represents a single Diatheke session and its
// current state.
message TokenData {
  bytes data = 1;

  // Session ID, useful for correlating logging between a
  // client and the server.
  string id = 2;

  // Additional data supplied by the client app, which will
  // be logged with other session info by the server.
  string metadata = 3;
}

// User supplied text to send to Diatheke for processing.
message TextInput {
  string text = 1;
}

// The result of executing a command.
message CommandResult {
  // The command ID, as given by the CommandAction
  string id = 1;

  // Output from the command expected by the Diatheke model.
  // For example, this could be the result of a data query.
  map<string, string> out_parameters = 2;

  // If there was an error during execution, indicate it
  // here with a brief message that will be logged by
  // Diatheke.
  string error = 3;
}

// Changes the current state of a Diatheke session to run at
// the specified story.
message SetStory {
  // The ID of the story to run, as defined in the
  // Diatheke model.
  string story_id = 1;

  // A list of parameters to set before running the given
  // story. This will replace any parameters currently
  // defined in the session.
  map<string, string> parameters = 2;
}

// The result of updating a session.
message SessionOutput {
  // The updated session token.
  TokenData token = 1;

  // The list of actions the client should take next,
  // using the session token returned with this result.
  repeated ActionData action_list = 2;
}

// Specifies an action that the client application should take.
message ActionData {
  oneof action {
    // The user must provide input to Diatheke.
    WaitForUserAction input = 1;

    // The client app must execute the specified command.
    CommandAction command = 2;

    // The client app should provide the reply to the user.
    ReplyAction reply = 3;

    // The client app should call the Transcribe method to
    // capture the user's input.
    TranscribeAction transcribe = 4;
  }
}

// This action indicates that Diatheke is expecting user input.
message WaitForUserAction {
  // True if the next user input must begin with a wake-word.
  bool requires_wake_word = 1;

  // True if the input is required immediately (i.e., in
  // response to a question Diatheke asked the user). When
  // false, the client should be allowed to wait indefinitely
  // for the user to provide input.
  bool immediate = 2;
}

// This action indicates that the client application should
// execute a command.
message CommandAction {
  // The ID of the command to execute, as defined in the
  // Diatheke model.
  string id = 1;
  map<string, string> input_parameters = 2;
}

// This action indicates that the client application should
// give the provided text to the user. This action may also
// be used to synthesize speech with the StreamTTS method.
message ReplyAction {
  // Text of the reply
  string text = 1;

  // TTS model to use with the TTSReply method
  string luna_model = 2;
}

// This action indicates that the client application should
// call the Transcribe method to capture the user's input.
message TranscribeAction {
  // The ID of the transcribe action, which is useful to
  // differentiate separate transcription tasks within a
  // single sesssion.
  string id = 1;

  // (Required) The ASR model to use for transcription.
  string cubic_model_id = 2;

  // (Optional) A Diatheke model to use for end-of-stream
  // conditions. If empty, the server will not be able to
  // automatically close the transcribe stream based on
  // conditions defined in the model, such as
  // a non-speech timeout or an "end-transcription" intent.
  // When empty, the stream must be closed by the client
  // application.
  string diatheke_model_id = 3;
}

// Data to send to the ASR stream. The first message on the
// stream must contain a `StreamASRConfig` message only, and
// all subsequent messages must contain audio only.
message StreamASRRequest {
  oneof data {
    // Configuration for ASR stream.
    StreamASRConfig config = 1;

    // Audio data to transcribe.
    bytes audio = 2;
  }
}

message StreamASRConfig {
  // Session data, used to determine the correct Cubic
  // model to use for ASR, with other contextual
  // information.
  TokenData token = 1;

  // Format of the audio to be sent for recognition.
  //
  // Depending on how they are configured, server instances of this service may
  // not support all the formats provided in the API. One format that is
  // guaranteed to be supported is the RAW format with little-endian 16-bit
  // signed samples with the sample rate matching that of the model being
  // requested.
  oneof audio_format {
    // Audio is raw data without any headers
    cobaltspeech.cubic.v5.AudioFormatRAW audio_format_raw = 2;

    // Audio has a self-describing header. Headers are expected to be sent at
    // the beginning of the entire audio file/stream, and not in every
    // `RecognitionAudio` message.
    //
    // The default value of this type is AUDIO_FORMAT_HEADERED_UNSPECIFIED. If
    // this value is used, the server may attempt to detect the format of the
    // audio. However, it is recommended that the exact format be specified.
    cobaltspeech.cubic.v5.AudioFormatHeadered audio_format_headered = 3;
  }
}

message StreamASRResponse {
  ASRResult asr_result = 1;
}

// The result from the ASR stream, sent after the ASR engine
// has endpointed or the stream was closed by the client.
message ASRResult {
  // The transcription.
  string text = 1;

  // Confidence estimate between 0 and 1. A higher number
  // represents a higher likelihood of the output being
  // correct.
  double confidence = 2;

  // True if a timeout was defined for the session's current
  // input state in the Diatheke model, and the timeout
  // expired before getting a transcription. This timeout
  // refers to the amount of time a user has to verbally
  // respond to Diatheke after the ASR stream has been
  // created, and should not be confused with a network
  // connection timeout.
  bool timed_out = 3;
}

// Data to send to the Transcribe stream. The first message on
// the stream must be a TranscribeAction, followed by audio data.
message TranscribeRequest {
  oneof data {
    // Configuration for Transcribe stream.
    TranscribeConfig config = 1;

    // Audio data to transcribe.
    bytes audio = 2;
  }
}

message TranscribeConfig {
  // Action defining the transcribe configuration.
  TranscribeAction action = 1;

  // Format of the audio to be sent for recognition.
  //
  // Depending on how they are configured, server instances of this service may
  // not support all the formats provided in the API. One format that is
  // guaranteed to be supported is the RAW format with little-endian 16-bit
  // signed samples with the sample rate matching that of the model being
  // requested.
  oneof audio_format {
    // Audio is raw data without any headers
    cobaltspeech.cubic.v5.AudioFormatRAW audio_format_raw = 2;

    // Audio has a self-describing header. Headers are expected to be sent at
    // the beginning of the entire audio file/stream, and not in every
    // `RecognitionAudio` message.
    //
    // The default value of this type is AUDIO_FORMAT_HEADERED_UNSPECIFIED. If
    // this value is used, the server may attempt to detect the format of the
    // audio. However, it is recommended that the exact format be specified.
    cobaltspeech.cubic.v5.AudioFormatHeadered audio_format_headered = 3;
  }
}

// The result from the Transcribe stream. Usually, several partial
// (or intermediate) transcriptions will be sent until the final
// transcription is ready for every utterance processed.
message TranscribeResponse {
  // The transcription.
  string text = 1;

  // Confidence estimate between 0 and 1. A higher number
  // represents a higher likelihood that the transcription
  // is correct.
  double confidence = 2;

  // True if this is a partial result, in which case the
  // next result will be for the same audio, either repeating
  // or correcting the text in this result. When false, this
  // represents the final transcription for an utterance, which
  // will not change with further audio input. It is sent when
  // the ASR has identified an endpoint. After the final
  // transcription is sent, any additional results sent on the
  // Transcribe stream belong to the next utterance.
  bool is_partial = 3;
}
